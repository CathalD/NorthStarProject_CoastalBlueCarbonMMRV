{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMclg1yopSZe4yZSm1gcXGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CathalD/NorthStarProject_CoastalBlueCarbonMMRV/blob/main/CoastalBlueCarbon_LargeScaleCovariateExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Hnx52aX0Rcx"
      },
      "outputs": [],
      "source": [
        "import ee"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigger the authentication flow.\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize the library.\n",
        "ee.Initialize(project='north-star-project-470316')"
      ],
      "metadata": {
        "id": "Cqpq2zlg0mQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "ewJ5fQNN1A7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. LOAD AND FILTER DATA\n",
        "FILENAME = 'global_cores_harmonized_VM0033.csv'\n",
        "try:\n",
        "    df = pd.read_csv(FILENAME)\n",
        "except FileNotFoundError:\n",
        "    print(\"❌ ERROR: File not found. Please upload the CSV.\")\n",
        "    raise\n",
        "\n",
        "# Filter for specific ecosystems and West Coast latitudes (excluding Alaska)\n",
        "target_ecosystems = ['EM', 'SG', 'FL']\n",
        "MIN_LAT, MAX_LAT = 46.5, 55.5\n",
        "\n",
        "df_subset = df[\n",
        "    (df['ecosystem'].isin(target_ecosystems)) &\n",
        "    (df['latitude'] >= MIN_LAT) &\n",
        "    (df['latitude'] <= MAX_LAT)\n",
        "].copy()\n",
        "\n",
        "# Prepare Features\n",
        "unique_locs = df_subset[['core_id', 'longitude', 'latitude']].drop_duplicates(subset='core_id').dropna()\n",
        "feature_list = []\n",
        "for _, row in unique_locs.iterrows():\n",
        "    geom = ee.Geometry.Point([row['longitude'], row['latitude']])\n",
        "    feature_list.append(ee.Feature(geom, {'core_id': str(row['core_id'])}))\n",
        "\n",
        "print(f\"✓ Processing {len(feature_list)} unique points (Lat {MIN_LAT}-{MAX_LAT})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMuxYCmaSJRl",
        "outputId": "87331ced-a80b-411c-dd55-2152e9d8b8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Processing 182 unique points (Lat 46.5-55.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 3. DEFINE LAYERS (BRIDGE 21)\n",
        "# ============================================================================\n",
        "\n",
        "# --- A. TOPOGRAPHY ---\n",
        "dem = ee.Image(\"NASA/NASADEM_HGT/001\").select(\"elevation\")\n",
        "elevation_m = dem.rename(\"elevation_m\")\n",
        "slope = ee.Terrain.slope(dem).rename(\"slope\")\n",
        "\n",
        "# Proxy for MHW (Mean High Water).\n",
        "# Global approximation: Elevation - 0.5m (Rough estimate of MHW above MSL)\n",
        "# In local script, use your precise local datum.\n",
        "elevationRelMHW = dem.subtract(0.5).rename(\"elevationRelMHW\")\n",
        "\n",
        "stack_topo = elevation_m.addBands(slope).addBands(elevationRelMHW)\n",
        "\n",
        "# --- B. SENTINEL-1 (SAR) ---\n",
        "s1 = (ee.ImageCollection(\"COPERNICUS/S1_GRD\")\n",
        "      .filterDate('2023-01-01', '2023-12-31')\n",
        "      .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n",
        "      .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n",
        "      .filter(ee.Filter.eq('instrumentMode', 'IW')))\n",
        "\n",
        "# Mean calculation (User requested Mean for SAR)\n",
        "s1_mean = s1.mean()\n",
        "\n",
        "vv = s1_mean.select('VV').rename('VV_mean')\n",
        "vh = s1_mean.select('VH').rename('VH_mean')\n",
        "ratio = s1_mean.select('VV').subtract(s1_mean.select('VH')).rename('VVVH_ratio')\n",
        "\n",
        "stack_s1 = vv.addBands(vh).addBands(ratio)\n",
        "\n",
        "# --- C. SENTINEL-2 (OPTICAL + TIDAL MASKING) ---\n",
        "\n",
        "def process_s2_image(image):\n",
        "    # 1. Cloud Masking\n",
        "    qa = image.select('QA60')\n",
        "    cloud_mask = qa.bitwiseAnd(1<<10).eq(0).bitwiseAnd(1<<11).eq(0)\n",
        "\n",
        "    # 2. Tidal/Water Masking (NDWI-based)\n",
        "    # If NDWI > 0.1, we assume it's inundated/water. We mask it out.\n",
        "    # This ensures the Median is calculated only from EXPOSED soil/veg.\n",
        "    ndwi_check = image.normalizedDifference(['B3', 'B8'])\n",
        "    tide_mask = ndwi_check.lt(0.1) # Keep only if NDWI < 0.1 (Land/Exposed)\n",
        "\n",
        "    # Combine masks\n",
        "    final_mask = cloud_mask.And(tide_mask)\n",
        "\n",
        "    return image.updateMask(final_mask).divide(10000)\n",
        "\n",
        "s2_coll = (ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\")\n",
        "           .filterDate('2023-01-01', '2023-12-31')\n",
        "           .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
        "           .map(process_s2_image))\n",
        "\n",
        "# Calculate Median of EXPOSED pixels\n",
        "s2 = s2_coll.median()\n",
        "\n",
        "# Bands\n",
        "B = s2.select('B2').rename('B')\n",
        "G = s2.select('B3').rename('G')\n",
        "R = s2.select('B4').rename('R')\n",
        "NIR = s2.select('B8').rename('NIR')\n",
        "SWIR1 = s2.select('B11').rename('SWIR1')\n",
        "SWIR2 = s2.select('B12').rename('SWIR2')\n",
        "\n",
        "# Indices\n",
        "ndvi = s2.normalizedDifference(['B8', 'B4']).rename('NDVI_median')\n",
        "ndbi = s2.normalizedDifference(['B11', 'B8']).rename('NDBI_median') # SWIR1/NIR\n",
        "evi_expr = '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))'\n",
        "evi = s2.expression(evi_expr, {'NIR': NIR, 'RED': R, 'BLUE': B}).rename('EVI_median')\n",
        "savi = s2.expression('((NIR - RED) / (NIR + RED + 0.5)) * 1.5', {'NIR': NIR, 'RED': R}).rename('SAVI_median')\n",
        "lswi = s2.normalizedDifference(['B8', 'B11']).rename('LSWI_median') # NIR/SWIR1\n",
        "mndwi = s2.normalizedDifference(['B3', 'B11']).rename('mNDWI_median') # Green/SWIR1\n",
        "\n",
        "# Tasseled Cap (Sentinel-2 Coefficients)\n",
        "brightness = s2.expression(\n",
        "    '0.3037*B2 + 0.2793*B3 + 0.4743*B4 + 0.5585*B8 + 0.5082*B11 + 0.1863*B12',\n",
        "    {'B2':B, 'B3':G, 'B4':R, 'B8':NIR, 'B11':SWIR1, 'B12':SWIR2}\n",
        ").rename('brightness')\n",
        "\n",
        "greenness = s2.expression(\n",
        "    '-0.2848*B2 - 0.2435*B3 - 0.5436*B4 + 0.7243*B8 + 0.0840*B11 - 0.1800*B12',\n",
        "    {'B2':B, 'B3':G, 'B4':R, 'B8':NIR, 'B11':SWIR1, 'B12':SWIR2}\n",
        ").rename('greenness')\n",
        "\n",
        "wetness = s2.expression(\n",
        "    '0.1509*B2 + 0.1973*B3 + 0.3279*B4 + 0.3406*B8 - 0.7112*B11 - 0.4572*B12',\n",
        "    {'B2':B, 'B3':G, 'B4':R, 'B8':NIR, 'B11':SWIR1, 'B12':SWIR2}\n",
        ").rename('wetness')\n",
        "\n",
        "stack_s2 = (B.addBands(G).addBands(R).addBands(NIR).addBands(SWIR1).addBands(SWIR2)\n",
        "            .addBands(ndvi).addBands(ndbi).addBands(evi).addBands(savi)\n",
        "            .addBands(lswi).addBands(mndwi)\n",
        "            .addBands(brightness).addBands(greenness).addBands(wetness))"
      ],
      "metadata": {
        "id": "rHttNcj9u7MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 4. BATCH EXTRACTION (SAFE MODE)\n",
        "# ============================================================================\n",
        "def extract_batch(image, features, name, batch_size=50):\n",
        "    results = []\n",
        "    print(f\"--- Extracting {name} ---\")\n",
        "    for i in range(0, len(features), batch_size):\n",
        "        batch = features[i : i + batch_size]\n",
        "        fc = ee.FeatureCollection(batch)\n",
        "        try:\n",
        "            # Spatially constrained extraction\n",
        "            if \"Sentinel\" in name:\n",
        "                res = image.clip(fc.geometry().buffer(100)).reduceRegions(collection=fc, reducer=ee.Reducer.first(), scale=30)\n",
        "            else:\n",
        "                res = image.reduceRegions(collection=fc, reducer=ee.Reducer.first(), scale=30)\n",
        "\n",
        "            data = res.getInfo()['features']\n",
        "            for f in data: results.append(f['properties'])\n",
        "            print(f\"   Batch {i} success\")\n",
        "        except Exception as e:\n",
        "            print(f\"   Batch {i} failed: {e}\")\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Run Extraction\n",
        "df_topo = extract_batch(stack_topo, feature_list, \"Topography\", 500)\n",
        "df_s1 = extract_batch(stack_s1, feature_list, \"Sentinel-1\", 100)\n",
        "df_s2 = extract_batch(stack_s2, feature_list, \"Sentinel-2\", 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6mI0NsAvEuf",
        "outputId": "e3676e67-0a9c-4631-f555-6d3f7d41adff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Extracting Topography ---\n",
            "   Batch 0 success\n",
            "--- Extracting Sentinel-1 ---\n",
            "   Batch 0 success\n",
            "   Batch 100 success\n",
            "--- Extracting Sentinel-2 ---\n",
            "   Batch 0 success\n",
            "   Batch 50 success\n",
            "   Batch 100 success\n",
            "   Batch 150 success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 5. MERGE\n",
        "# ============================================================================\n",
        "def merge_df(main, sub):\n",
        "    if sub.empty: return main\n",
        "    cols = ['core_id'] + [c for c in sub.columns if c not in ['core_id', 'system:index']]\n",
        "    return pd.merge(main, sub[cols], on='core_id', how='left')\n",
        "\n",
        "final = df_subset.copy()\n",
        "final['core_id'] = final['core_id'].astype(str)\n",
        "final = merge_df(final, df_topo)\n",
        "final = merge_df(final, df_s1)\n",
        "final = merge_df(final, df_s2)\n",
        "\n",
        "final.to_csv('global_cores_with_gee_covariates.csv', index=False)\n",
        "files.download('global_cores_with_gee_covariates.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_vjdJoUavTOU",
        "outputId": "3ecd1bbc-522f-45a7-b0fc-30782f1990f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6875c26a-21fc-423b-b52c-7118436b0a05\", \"global_cores_with_gee_covariates.csv\", 304380)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}